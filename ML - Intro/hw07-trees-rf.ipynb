{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Интеллектуальный анализ данных – весна 2022\n",
    "\n",
    "# Домашнее задание 7: Деревья. Случайный лес\n",
    "\n",
    "Правила:\n",
    "\n",
    "- Домашнее задание оценивается в 10 баллов (+1 бонусный балл).\n",
    "\n",
    "\n",
    "- Можно использовать без доказательства любые результаты, встречавшиеся на лекциях или семинарах по курсу, если получение этих результатов не является вопросом задания.\n",
    "\n",
    "\n",
    "- Можно использовать любые свободные источники с обязательным указанием ссылки на них.\n",
    "\n",
    "\n",
    "- Плагиат не допускается. При обнаружении случаев списывания, 0 за работу выставляется всем участникам нарушения, даже если можно установить, кто у кого списал.\n",
    "\n",
    "<!-- ![](meme.jpg) -->\n",
    "<img src=\"meme.jpg\" alt=\"Drawing\" style=\"width: 700px;\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 1: Основы построения решающие дерева (1.5 балла)\n",
    "\n",
    "В этой части все расчёты необходимо реализовывать в виде запрограммированных формул, например, на `numpy`. **Нельзя использовать готовые реализации**. Например, если в задании требуется рассчитать энтропию, то требуется в каком-то виде релизовать расчёт по формуле, но нельзя использовать готовую реализацию `some_module.entropy()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.1 (0.5 балла)** Пусть известно, что в вершину решающего дерева попали 10 объектов, 8 из которых имеют метку класса $k_1$, а 2 имеют метку класса $k_2$. Рассчитайте энтропию такого распределения классов (с натуральным логарифмом). Ответ округлите до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.72\n"
     ]
    }
   ],
   "source": [
    "k1 = 8\n",
    "k2 = 2 \n",
    "s = k1 + k2 \n",
    "\n",
    "print(round(-k1/s * np.log2(k1/s) - k2/s * np.log2(k2 / s), 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.2 (0.5 балла)** Пусть дополнительно известно, что вершина из предыдущего задания не является листовой и возможно такое разбиение, что в левое поддерево попадут все объекты класса $k_1$, а в правое - класса $k_2$. Посчитайте критерий информативности:\n",
    "\n",
    "$$\n",
    "Q(R_m, j, t) = H(R_m) - \\frac{|R_\\ell|}{|R_m|}H(R_\\ell) - \\frac{|R_r|}{|R_m|}H(R_r),\n",
    "$$\n",
    "\n",
    "где $R_m$ - множество объектов в разбиваемой вершине, $j$ - номер признака, по которому происходит разбиение, $t$ - порог разбиения, $R_\\ell$ - множество объектов в левом поддереве, $R_r$ - множество объектов в правом поддереве.\n",
    "\n",
    "Теперь в качестве $H(R)$ будем использовать индекс Джини:\n",
    "\n",
    "$$\n",
    "H(R) = \\sum_{k=1}^J p_k(1-p_k),\n",
    "$$\n",
    "где $J$ – общее количество классов (в нашем случае, $J = 2$).\n",
    "\n",
    "Ответ округлите до двух знаков после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def gini(y):\n",
    "    ps = np.bincount(y) / len(y)\n",
    "    return np.sum(ps * (1 - ps))\n",
    "\n",
    "def Q(X, y, j, t, H=gini):\n",
    "    if X.ndim > 1:\n",
    "        x = X[:,j] # выделили только признак \n",
    "    else:\n",
    "        x= X \n",
    "    left = y[x < t]\n",
    "    right = y[x > t]\n",
    "    count = len(y)\n",
    "    return H(y) - len(left) / count * H(left) - len(right) / count * H(right)\n",
    "\n",
    "y = np.array([0] * 8 + [1] * 2) \n",
    "X = y.reshape(-1,1)\n",
    "Q(X, y, 0, 0.5) # вообще очев, будет только H(y), так как разделения чистые и H(left) = H(right) = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 1.3 (0.5 балла)** Пусть при построении дерева образовалась листовая вершина с 10 объектами, значения целевой переменной для которых следующие: [1, 10, 5, 18, 100, 30, 50, 61, 84, 47] (решается задача регрессии). Чему будут равны предсказания модели для этих объектов?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40.6"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([1, 10, 5, 18, 100, 30, 50, 61, 84, 47]).mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 2: Решающие деревья (4.5 балла)\n",
    "\n",
    "В этой части мы напишем и протестируем собственную реализацию решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from typing import Dict, List, Tuple, Union"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.1 (1.5 балла)** Реализуйте функцию `find_best_split()`, которая должна находить оптимальное разбиение подмножества обучающей выборки в соответствии с информационным критерием из **Задания 1.2**. В качестве меры хаотичности $H(R)$ для задачи регрессии испольуйте дисперсию подвыборки, а для задачи классификации – критерий Джини (определён в том же задании).\n",
    "\n",
    "Для категориальных признаков применяется наивный алгоритм разбиения: мы пытаемся найти одно значение, разбиение по которому сильнее всего увеличит критерий информативности. Иными словами, объекты с конкретным значением признака отправляем в левое поддерево, остальные - в правое. Обратите внимание, что это далеко не оптимальные способ учёта категориальных признаков. Например, можно было бы на каждое значение категориального признака создавать отдельное поддерево или использовать более сложные подходы. Подробнее об этом можно прочитать в конспектах [лекций](https://github.com/esokolov/ml-course-hse/blob/master/2019-fall/lecture-notes/lecture07-trees.pdf) по машинному обучению на ПМИ (раздел «Учёт категориальных признаков»).\n",
    "\n",
    "В качестве подсказок реализации можете пользоваться кодом из бонусной части семинара по решающим деревьям.\n",
    "\n",
    "**Бонус:** Разрешается делать цикл для перебора порогов, но возможна имплементация без него. За имплементацию без цикла – **бонус 1 балл**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_split(\n",
    "    feature_vector: Union[np.ndarray, pd.DataFrame], \n",
    "    target_vector: Union[np.ndarray, pd.Series],\n",
    "    task: str = \"classification\",\n",
    "    feature_type: str = \"real\"\n",
    ") -> Tuple[np.ndarray, np.ndarray, float, float]:\n",
    "    \"\"\"\n",
    "    Указания:\n",
    "    * Пороги, приводящие к попаданию в одно из поддеревьев пустого множества объектов, не рассматриваются.\n",
    "    * В качестве порогов, нужно брать среднее двух сосдених (при сортировке) значений признака\n",
    "    * Поведение функции в случае константного признака может быть любым.\n",
    "    * При одинаковых приростах Джини или дисперсии нужно выбирать минимальный сплит.\n",
    "    * За наличие в функции циклов балл будет снижен. Векторизуйте! :)\n",
    "\n",
    "    :param feature_vector: вещественнозначный вектор значений признака\n",
    "    :param target_vector: вектор классов объектов,  len(feature_vector) == len(target_vector)\n",
    "    :param task: либо `classification`, либо `regression`\n",
    "    :param feature_type: либо `real`, либо `categorical`\n",
    "    \n",
    "    :return thresholds: отсортированный по возрастанию вектор со всеми возможными порогами, по которым объекты можно\n",
    "     разделить на две различные подвыборки, или поддерева\n",
    "    :return ginis: вектор со значениями критерия Джини для каждого из порогов в thresholds len(ginis) == len(thresholds)\n",
    "    :return threshold_best: оптимальный порог (число)\n",
    "    :return gini_best: оптимальное значение критерия Джини (число)\n",
    "    \"\"\"\n",
    "    # В задании, вроде, логическая ошибка. \n",
    "    # Просят использовать критерий информативности, \n",
    "    # но надо вернуть критерий Джини и когда он минимален, \n",
    "    # подразумевая, что все-таки не по информативности надо максимизировать, \n",
    "    # а минимизировать по критерию Джини.\n",
    "\n",
    "    # Я игнорирую критерий Джини и возвращаю информативность \n",
    "\n",
    "    if task == \"regression\":\n",
    "        impurity_func = np.var\n",
    "    elif task == \"classification\":\n",
    "        impurity_func = gini \n",
    "    else:\n",
    "        raise ValueError(\"Чет не то с task\")\n",
    "\n",
    "    if feature_type == \"categorial\":\n",
    "        thresholds = np.unique(feature_vector)\n",
    "        def split(t):\n",
    "            left = target_vector[feature_vector == t]\n",
    "            right = target_vector[feature_vector != t]\n",
    "            return Q(feature_vector, target_vector, 0, t, H=impurity_func)\n",
    "    else:\n",
    "        thresholds = np.unique(feature_vector) # оно соритурует тоже \n",
    "        # трешхолды можно брать как средние между текущими значениями \n",
    "        thresholds = np.convolve(thresholds, np.ones(2) * 0.5, 'valid')\n",
    "        def split(t):\n",
    "            left = target_vector[feature_vector < t]\n",
    "            right = target_vector[feature_vector > t]\n",
    "            return Q(feature_vector, target_vector, 0, t, H=impurity_func)\n",
    "\n",
    "    # фактически это будет жульничеством, но я воспользуюсь np.vectorize \n",
    "    # эта функция повзоляет прогнать функцию по каждому значению массива, заменя for\n",
    "    # зато удовлетворяет условию бонусного задания :)\n",
    "    ginis = np.vectorize(split)(thresholds)\n",
    "    best = np.argmax(ginis) # если используем Q, мы максимизируем информативность \n",
    "    return thresholds, ginis, thresholds[best], ginis[best]\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эту функцию можно протестировать на датасете `California`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MedInc</th>\n",
       "      <th>HouseAge</th>\n",
       "      <th>AveRooms</th>\n",
       "      <th>AveBedrms</th>\n",
       "      <th>Population</th>\n",
       "      <th>AveOccup</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.3252</td>\n",
       "      <td>41.0</td>\n",
       "      <td>6.984127</td>\n",
       "      <td>1.023810</td>\n",
       "      <td>322.0</td>\n",
       "      <td>2.555556</td>\n",
       "      <td>37.88</td>\n",
       "      <td>-122.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.3014</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.238137</td>\n",
       "      <td>0.971880</td>\n",
       "      <td>2401.0</td>\n",
       "      <td>2.109842</td>\n",
       "      <td>37.86</td>\n",
       "      <td>-122.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.2574</td>\n",
       "      <td>52.0</td>\n",
       "      <td>8.288136</td>\n",
       "      <td>1.073446</td>\n",
       "      <td>496.0</td>\n",
       "      <td>2.802260</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.6431</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.817352</td>\n",
       "      <td>1.073059</td>\n",
       "      <td>558.0</td>\n",
       "      <td>2.547945</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.8462</td>\n",
       "      <td>52.0</td>\n",
       "      <td>6.281853</td>\n",
       "      <td>1.081081</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.181467</td>\n",
       "      <td>37.85</td>\n",
       "      <td>-122.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MedInc  HouseAge  AveRooms  AveBedrms  Population  AveOccup  Latitude  \\\n",
       "0  8.3252      41.0  6.984127   1.023810       322.0  2.555556     37.88   \n",
       "1  8.3014      21.0  6.238137   0.971880      2401.0  2.109842     37.86   \n",
       "2  7.2574      52.0  8.288136   1.073446       496.0  2.802260     37.85   \n",
       "3  5.6431      52.0  5.817352   1.073059       558.0  2.547945     37.85   \n",
       "4  3.8462      52.0  6.281853   1.081081       565.0  2.181467     37.85   \n",
       "\n",
       "   Longitude  \n",
       "0    -122.23  \n",
       "1    -122.22  \n",
       "2    -122.24  \n",
       "3    -122.25  \n",
       "4    -122.25  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = fetch_california_housing()\n",
    "X = pd.DataFrame(data=data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = data[\"target\"]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.526, 3.585, 3.521, ..., 0.923, 0.847, 0.894])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведите график зависимости значения критерия ~~ошибки~~ информативности от порогового значения при разбиении вершины по признаку `MedInc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAArBklEQVR4nO3dd3zV5dnH8c+VPSEkJIyQkABhCYoYlgsQVByVVmtFcWvV1tXWUaxPbatt1Wp98LHUUa1Wq0VttUVZCrJUEIKg7BX2DHsEMq/nj3NIAyTkAOfkPuN6v17nxW8l+QJJrvO7f/cQVcUYY0zkinIdwBhjjFtWCIwxJsJZITDGmAhnhcAYYyKcFQJjjIlwMa4DnKjmzZtrXl6e6xjGGBNS5s6du11VM+s6F3KFIC8vj6KiItcxjDEmpIjI2vrOWdOQMcZEOCsExhgT4awQGGNMhLNCYIwxEc4KgTHGRDgrBMYYE+GsEBhjTISzQmACbtmWfeSNGMsdb9r4D2OCkRUCEzDV1UrHR8dz8cjpAHyyeCt5I8YyeclWx8mMMbVZITABkTdiLO1+MY7yqupjzt32tyIqq6p5dUYxVdXHLoykqtiCScY0npCbYsIEp10HylEgPTmO+0fPO+LcH646nR/0yuFgeRVdHpsAQIdHxwPw27FLAFj95KWICGu2H2DAs1MBWPPUZY2W35hIFtBCICJDgOeBaOBVVX2qnuuuAv4J9FJVa0gOEf/76XLW7DjAf+Zvqjl2/6CCmv1fXt6VG/q2JS7Gc+OZGBfNtIcG0P+Zqcd8rkc+WEBOehLPTFxWc2zdjlJyM5IC+5cwxgSuaUhEooFRwCVAV+BaEelax3WpwP3AV4HKYvxv4cY9PD95xRFFAOD5yStqtm87N7+mCBzWNiOZ0Xf0BSAnPZELu7YAYPSc9UcUAYApy7ZZE5ExjSCQzwh6AytVtVhVy4HRwNA6rnsCeBo4FMAsxk8Ot99f/sLnx73upet71nuub7sMVj95KTMevoC/3FhIfvPkI85//vOBAPxqzCLyHxnHV8U7Tj24MaZegWwaygbW19rfAPSpfYGI9ARyVHWsiDxU3ycSkTuAOwByc3MDENX4Yt+hCrr/+pMjjtVuxz9UUcWyLfs4Iyetwc8lIjXbUx4cwNMTllLYthn9O2YSE33k+5NrXpnFo5d24Yfntzu1v4Axpk7Oeg2JSBTwHPBAQ9eq6iuqWqiqhZmZda6rYBrB8FePbL0bc885R+wnxEb7VATq8vMhnRnUpUVNEVj8+MW8dVvvmvO/G7eE4pL9J/W5jTHHF8hCsBHIqbXfxnvssFSgGzBVRNYAfYExIlIYwEzGR9XVSoW362dVtZI3YizfbthTc/6egR04vU1awL5+UlwM5xVksuapy2if6Wk6uuCP0wL29YyJZIFsGpoDFIhIPp4CMAy47vBJVd0DND+8LyJTgQet15B7qkq7X4yr81x2WiJfjLigUfNMfmAAeSPGAjB12TYGdMpq1K9vTLgL2B2BqlYC9wATgSXAe6q6SEQeF5ErAvV1zanLf6TuIvDNYxc1ehE47IMfnw3Aza/PcfL1jQlnAR1HoKrjgHFHHXusnmsHBDKL8U1FHSOBU+NjePfOfjRNinWQyKNnbrOa7W37DpGVmuAsizHhxkYWmyMMfu6/7fDBNrL35rPzeOPLNfT+3WSKf38pUVHS8AcZYxpkcw2ZI6zdUQrAu95BX8Hk11ecVrP9nT8dfxyDMcZ3VggMAMUl+2seyAL0aZfhME39XhzuGai2aNPeI/IaY06eFQKDqh7RNfP5YT3chWnAJd1bHbFvxcCYU2eFwBzTS+iKM1o7SuKbFb+75Ij92at3OkpiTHiwQhDh5qz57y/RpU8MYc1Tlx0x/UMwio2O4sta3Vh/8PJMm5zOmFNghSCCqSpXvzQTgCe+242E2GjHiXzXOi2R1U9eWrP/m48WO0xjTGizQhDBrnl5Vs32db1DbzI/EWH+YxcC8MaXazhQVuk4kTGhyQpBhNqwq5TZ3mahL0ZcQHSI9slPS4ojJz0RgNN+NZHqOpa+NMYcnxWCCHXu01NqtrPTEh0mOXXTHhxYs93uF+P4bOlWh2mMCT1WCCLM5j0Hj+hyGWyjh09GVJQw+9FBNfu3vlFkdwbGnAArBBGm35Of1Ww/PKSTwyT+lZWacMTD44mLtjhMY0xosUIQoYb3yeXHAzq4juFXIlIzO+rRaykbY+pnhSBClFVWcenzM2r2f/e97g7TBM7h5x0TFm1hw65Sx2mMCQ1WCCJEp/+ZwOLNewF4/ZZejtME1o8HtAfg/aINjpMYExqsEESggWG+wteDF3mefTw/eYWNLTDGB1YIIsDG3QcB6JXXjMkP9HecJvCiooRR13lmKf3NR4scpzEm+FkhiADnPOXpKTS0RzbtM1Mcp2kcQ7q1BOC9og3sOlDuOI0xwc0KQZjbsudQzfbwPqE3jcTJio4S/ueyLgCc+cSnjtMYE9ysEIS5vk9OBmD6QwODflZRf7v9vHY126OmrHSYxJjgZoUgjM1YUVKznZuR5DCJO5//3DP9xJ8+W2lTVRtTDysEYeyG12YD8MK1ZzpO4k6bZkn8dHBHDlZU8ei/F7qOY0xQskIQpmrPJ/SdIF9xLNDu7O9pInrnq3WOkxgTnKwQhKHaE65N+tn5DpMEh9oL7pTsK3OYxJjgZIUgDM1YuR2Aa3vn0iEr1XGa4JCRHAfA0xOWOk5iTPCxQhCG3pq5lozkOH59RVfXUYLGhJ947oyWbtnrOIkxwccKQZhZVbKfSUu2ctnprYiPCZ01iAMtMzUegIUb9zJ9eUkDVxsTWawQhJG1Ow4w6I/TAE+zkDnSr77juUO68a+zHScxJrhYIQgj/Z+ZWrPdpVUTd0GC1C3n5NMkIQaAhRv3OE5jTPCwQhAmfvvx4prt128O72mmT8XoO/oBcPkLnztOYkzwsEIQJrbs9cwp9PjQ0xjYObynmT4VXVs3ITfdM8p62ZZ9jtMYExysEISJj7/dDMCN/fLcBgkBb93WG4CLR053nMSY4GCFIAzc8NpXriOElLYZyTXbv7RpJ4yxQhAOZqzwDCC7+qw2jpOEjg9/fDYAb81a6ziJMe5ZIQhxtaeTeObqMxwmCS1n5jbjzNw0AHbawjUmwlkhCHGz1+wE4Oaz89wGCUF39fcscj/EnhWYCGeFIMQNe2UWALefl+84Sei5+DTPcpbb9pVRUVXtOI0x7lghCBNtmkXmwjOn6qXrzwJgytJtjpMY444VghC2afdBAHrnpztOEroGdfGMubjjrblUVdsKZiYyBbQQiMgQEVkmIitFZEQd5+8SkQUiMl9EPhcRmy7zBDzhHU380MWdHCcJXbHRUZyRkwbAoD9OdZrFGFcCVghEJBoYBVwCdAWureMX/Tuq2l1VewB/AJ4LVJ5wNH7hFgBOb9PUcZLQ9uGPPF1J1+woZd2OUsdpjGl8gbwj6A2sVNViVS0HRgNDa1+gqrUnh08G7N78JNh006cmKkp4+QbPs4KfvjffbRhjHAhkIcgG1tfa3+A9dgQRuVtEVuG5I7ivrk8kIneISJGIFJWU2Fzy4Jly2vjPxae1pFt2E+au3cWWPYdcxzGmUTl/WKyqo1S1PfBz4H/queYVVS1U1cLMzMzGDRikiks8hcBmGvWfF67tCcDg56ahajenJnIEshBsBHJq7bfxHqvPaOC7AcwTVm55Yw4AfdpZjyF/yW+ezCXdWrK/rJKXpxe7jmNMowlkIZgDFIhIvojEAcOAMbUvEJGCWruXASsCmCdsHO42CpAUF+MwSfh58sruADw13ha5N5EjYIVAVSuBe4CJwBLgPVVdJCKPi8gV3svuEZFFIjIf+BlwU6DyhJOzn/oMgPH3n+c4SfhJS4rjjvPbAfB/k+19iYkMAX07qarjgHFHHXus1vb9gfz64WhjrbuBzi1THSYJXz8ZXMAr04t57tPl9MpLp1/7DNeRjAko5w+LzYk592nP3cCvv9MVEXGcJjwlxcXULHR/7V9mMda76I8x4coKQYg53JnlJpttNKBuOSefK8/09Hb+1RhbvMaEN3vSGEK+Wb8bgOYp8XY30Aieu6YHZZXVjF2wmYqqamKj7X2TCU/2nR1Cho76AoA//sAWoGksAzt7JqW7f/Q8x0mMCRwrBCGi9kpk/TvaoLrGclVPT/PQuAVbOFBW6TiNMYFhhSBEzPM2CxVkpbgNEmFEpGZswWm/msiSzXsb+AhjQo8VghDxySLPTKMvXHem4ySR59reuXTP9szwesnzM9i2z+YiMuHFCkGIWLhpDwVZKXRu2cR1lIj00b3n8mtvl9J737HnBSa8WCEIAXsPVfBV8U4u8K6mZdy4+Zx8+nfM5KvVO+2uwIQVKwQh4IXJK6isVgZ1buE6SsT75eWeu4JXZ6x2nMQY/7FCEAJmFe8EoLBtM8dJTIesFAZ3acGH8zZaLyITNqwQBLlDFVUs2LiHlPgYoqJsEFkwuPXcPEr2lXHL63NcRzHGL6wQBLl563YD0CvP7gaCxdntm9OxRQqz1+xk5KTlruMYc8qsEAS5mcU7iBIYOcy6jQaT127yrAw3ctIKe3BsQp4VgiD3f5NXUJCVStPEWNdRTC056Un860f9ALjxtdmO0xhzaqwQBLHD7zSXbd3nOImpy1lt07mxX1uWbtnHR99sch3HmJNmhSCIzV7t6S10+7n5jpOY+jx6WRcA7v3HPCqqqh2nMebkWCEIYiu37UcE7h9c0PDFxon4mGh+eJ6nUP/Ph7ZugQlNVgiC2Lx1u+mYlUpqgj0fCGaPXNKF5Lho3i1aT8m+MtdxjDlhVgiCVFW1Mm15Cadl29xCwS4qSnj3Ts+D4ze+tBHHJvRYIQhSX67aDngKggl+3bKb0r9jJqOmrGLKsm2u4xhzQqwQBKnDvVDu6t/ecRLjq8eHngbAX6YXO05izInxac1iEckEfg50BRIOH1fVCwKUK+K9V7QBgC6trGkoVLTNSKZ3XjoLNu6hulptShATMny9I3gbWALkA78B1gA20UqAWHNQ6Pr+WW3Yd6iS4u0HXEcxxme+FoIMVX0NqFDVaap6K2B3AwEyes46AG6z8QMhp2fbNAC+XrfLbRBjToCvhaDC++dmEblMRM4E0gOUKeIt3ewZSXxt7xzHScyJatc8hbSkWN4vWu86ijE+87UQ/FZEmgIPAA8CrwI/DViqCPfveRsBzy8VE1qiooRhvXKZs2YXK7ftdx3HGJ/4VAhU9WNV3aOqC1V1oKqeBXwS4GwRa593wRN72BiabjknD4A/T13pNogxPvKpEIjIY0ftD8YeFgfErgPlAFxTaM1CoapFkwROa92ED77eyBcrt7uOY0yDfG0aaikiL4pIcxH5G/AwMDSAuSLWX2Z4+qAP7mrrE4eyPw/vCcAfJi5znMSYhvnaNPRjYBOwHpipqhepqo2aCYDt+z1z1ZxX0NxxEnMq2mYkc1XPNizZtLfmLs+YYOVr09CVwCJgEnC9iFzpPWb87PBAsoTYaMdJzKm6/bx8yquqGb9wi+soxhyXr01D3/G+tgMrvNuXBypUpOvcMtV1BOMHnVum0qJJPJ8stkJggptPU0yo6i2BDmJg856DgGd0qgl9IsJ1vdvyv5OWs2TzXpsuxASt494RiMht3j/biMiHIrLN+/qXiNhvKz/r9+RnAPRs28xxEuMvN5+dR3JcNC9OXeU6ijH1aqhp6EfeP18HxgCtva+PgL8GMFdEio32jBs4MyfNbRDjN02TYhnWO5exCzazxuYfMkGqoUJQJiLxQAtVfV1VK72vN4CswMeLHIcqqogS4ZZz8hCxgWTh5Pbz8hHg7a/Wuo5iTJ0aKgT/BkYA20TkehGJ9r6GA/sCni6CFK3ZRVlltXUbDUOtmiZyYdcWvDVrLXsOVjT8AcY0soYKwR+BaDzTT78JlAElwI3AbYGNFllmrCwhNlrok5/hOooJgBv6tuVQRXXNgkPGBJPjFgJVrVbVx1S1vapGqWqMqqar6sWquryhTy4iQ0RkmYisFJERdZz/mYgsFpFvRWSyiLQ9lb9MKHt5WjEiQnK8Tx25TIjp1z6D7LREJi6yrqQm+Pi6QtnP6jquqs8d52OigVHAhcAGYI6IjFHVxbUumwcUqmqpiPwI+ANwja/hw8VO78jTPvk2s3e4EhGG9crhj58uZ8qybQzsZI/YTPDwdUDZL/E0B6Ue9Tqe3sBKVS1W1XJgNEfNT6SqU1S11Ls7C4jILqnLt3oet9x+XjvHSUwgXeNdX+L1L9a4DWLMUXwtBO2BT4FBwBeq+htV/U0DH5ONZ26iwzZ4j9XnNmB8XSdE5A4RKRKRopKSEh8jh45hr8wCoKsNOAprWakJ3NSvLdOXl/Dtht2u4xhTw9dJ53aq6kPAMOBqEZkgIr38FUJErgcKgWfq+fqvqGqhqhZmZmb668sGnczUeNcRTIA9NKQzAFf86QsOVVQ5TmOMh6+Tzn0kImOAl/AMKMvF05RzPBuB2pPqt/EeO/pzDwYeBa5Q1TJf8oSTyqpqAHrn2fOBSJASH8Ot53jWov5yla1VYIKDr11Unj2Jzz0HKBCRfDwFYBhwXe0LvGsfvwwMUdVtJ/E1Qt7izXsBm3Y6kjw8pBPvF63nFx8sZOJP02maGOs6kolwvjYNTavr1cDHVAL3ABOBJcB7qrpIRB4XkSu8lz0DpADvi8h8711HRPlk0VYAhvY43uMTE04SYqMZNbwn2/eX8cB7813HMcbn7qMlgNY+BFSr6nGX0VLVccC4o449Vmt7sO9Rw9O4BZsByElPdJzENKbzO2ZyzwUdGDlpBQs37qFbdlPXkUwE83mpSqDVUa8GB5SZhhV7JyKz+YUiz/V9PeMnn56wFFVt4GpjAsfXpqGqo16VHHmHYE5ChfdBcVKcrUYWiZqnxHNh1xbMWLGdid4mQmNc8LXX0BQR+azWawrQPcDZwt7CjXsAeHxoN8dJjCt/Ht6TlPgYPv7W5iAy7vjaa+jBo/YF+Iufs0Scu/4+F4C2GUmOkxhXYqOjuLJnNm/OXMtPBu+nQ1aK60gmAvnaNDT3qFcRNg31Kdu61zNsopeNIYho91zQgbiYKP48daXrKCZC+dpr6AWO7TVkE+Ocgn2HPPPS39W/veMkxrWs1ARuOzefF6euIjMlnkcu7eI6kokwvvYaWoynl9By73YRntHA5iR98LVnkHW7zGTHSUww+MngAgBenl7MnlJbvMY0roYWr48RkT8ATwC3el+/BboB7wQ+XvjauPsgAIO7HHcohokQ8THR/OtHZwPwzux1jtOYSNPQHcEzQDqQr6o9VbUnniahptQzQZzxzda9h8hOSyQ9Oc51FBMkzmrbjAGdMnl6wlLmrdvlOo6JIA0VgsuBH6pqzYNhVd0L/Ai4LJDBwt2KrdZDxBzriaHdaN00gatfmmkDzUyjaagQqNbxnaiqVdiAspNWVa2sKtlPgRUCc5Sc9CQ+uvdcBnXJ4sWpqxg1xXoSmcBrqBAsFpEbjz7oXT9gaWAihb8Nu0opq6ymoIUVAnOsjJR4Xrr+LHrnp/PsJ8spLa90HcmEuYYKwd3A3SIyVUT+6H1NA+7D0zxkTsKKrfsB6JDV0GqfJlKJCDf288xFdOsbcxynMeHuuIVAVTeqah/gcWCN9/W4qvZW1WMWmTG+WbHtcCGwOwJTv8tPb815Bc2ZVbyTSYttLiITOL6OLP5MVV/wviYHOlS4W7FtHy2axNuCJKZBr95USOeWqfz03fmsKtnvOo4JU74OKDN+tHzrPjq2sGYh07D4mGheu7kXFdXV/PDNInYeKHcdyYQhKwSNrKKqmuVb9tO1VRPXUUyIyE5L5Jnvn0FxyQEe/2gR1dXWYc/4lxWCRraqZD/lVdV2R2BOyHfOaM19gwr49/xN9PztpxSt2ek6kgkjVgga2afeBUhy0m3qaXNifjq4gLv6t2d3aQXff2mmzVZq/MYKQSNbt7OUZkmx9Mpr5jqKCTEiwohLOjPj4YEAjJy0gvHeNa+NORVWCBrZ+3M3kJIQY2sUm5OWk57E7EcHUZCVwn2j5zF3rTUTmVNjhaARlVd61ijOy7Cpp82pyUpN4O3b+9CiSQI3vDabb9bvdh3JhDArBI1o/ELPbfz5BZmOk5hwkJYUxxu39CY5Pobb/lZEyb4y15FMiLJC0IhmrtoBwMWntXScxISLDlkp/OXGQvYequDyF2bYoDNzUqwQNKJPFh/uMZToOIkJJz1y0njvzn7sP1TJkJHTmb68xHUkE2KsEDSiw6NC7UGx8bceOWlMeXAA7TM9D5CXbN7rOpIJIVYIGskubxF46OJOjpOYcJXVJIGXrj8LVbjk+Rn86O9zOVRR5TqWCQFWCBrJ3LWepQcL29r4ARM4ec2TmfxAf+4bVMD4hVu44NmprN1xwHUsE+SsEDSSuet2ERMlnJGT5jqKCXPNU+L52YUdefXGQjbvPcRVL37Ji1NXUVFV7TqaCVJWCBrJwo176NgilYTYaNdRTIQY3LUF793ZD1V4esJSuj42gbwRY3nnq3VU2cR1phYrBI1AVVm8aS/dsm3GUdO4euWlM/ORQbw4vCdXF+YA8IsPF3D/6HmOk5lgYoWgEWzdW8aOA+U29bRxIi4miku6t+L33+vO6icv5e6B7fn4283Mt9HIxssKQSO4+52vAejeJs1tEBPxRIQfD+hAYmw0L09bZWsbGMAKQaM43GOoSytbg8C4lxwfw5392zF+4RZ+/PbXtuqZIcZ1gHB3+KFcu+bJJMXZP7cJDvcPKiAhNpqnJyxlwqItpCXFckPftjxwkY1ziUR2RxBgh9thz+9oE82Z4CEi3NW/Pf+862wevKgjAC98tpIpy7Y5TmZcsEIQYLNXe+aKv29QgeMkxhzrrLbNuOeCAmb/YjBtM5IYOWmF60jGASsEAfb+3PUApCfHOU5iTP3iYqK4oW9bvlm/m6l2VxBxrBAEkKpSXGLD+01ouLFfHtlpiTz7yTJUrTdRJAloIRCRISKyTERWisiIOs6fLyJfi0iliHw/kFlcWLBxD+B5MGdMsIuLieKuAe1ZuHEvi2320ogSsEIgItHAKOASoCtwrYh0PeqydcDNwDuByuFS0RpPt9HvnZntOIkxvrmseytS4mN43p4VRJRA3hH0BlaqarGqlgOjgaG1L1DVNar6LRCWs2Et2LiHZkmxtM1Ich3FGJ+kJ8dx5/nt+GTxVvJGjGXPwQrXkUwjCGQhyAbW19rf4D12wkTkDhEpEpGikpLQWH1JVfli5XbOLci0hWhMSLntvPya7fOe/oyV22z5y3AXEg+LVfUVVS1U1cLMzNDoj1+8/QDb9pXRr12G6yjGnJCkuBiW//YS7r2gA7HRUXxv1Bes31nqOpYJoEAWgo1ATq39Nt5jEWFWsWeh+n7trRCY0BMXE8UDF3Xi3Tv7UVmtPDl+ietIJoACWQjmAAUiki8iccAwYEwAv15QmblqBy2axJNnzwdMCOuQlcKw3jl8smhrzXKrJvwErBCoaiVwDzARWAK8p6qLRORxEbkCQER6icgG4GrgZRFZFKg8jelQRRUff7uZiiq15wMm5H23RzaV1cprn692HcUESEBnQVPVccC4o449Vmt7Dp4mo7Dy+YrtAAzt0dpxEmNO3Rk5afTJT+eV6cUU5jVjQKcs15GMn4XEw+JQM6t4B3HRUfx8SGfXUYzxiz9d15MOWSnc88485q7d6TqO8TMrBAFQtHYXPXLSbH1iEzYyU+N57eZCMlPjuerFmYyctNx1JONHVgj8rLyymvnrd9O9TVPXUYzxq1ZNExl9R18GdMpk5KQVDBk5nQNlla5jGT+wQuBnh2dubJYU6ziJMf7XokkCr95YyKXdW7J0yz6u+NPnbNp90HUsc4qsEPjZks37ALihb57bIMYESEx0FH8efhbv3N6HDbsO8uiHC2pW4jOhyQqBn81es4MurZrQ1O4ITJg7u0Nz7htUwJRlJTxvzwxCmhUCP6qoqubrtbvpk5/uOooxjeLugR3o2y6dd4vWs7vUBpyFKisEfrRh10EOVlRxWusmrqMY02juu6CAXQcquOn1OVRUheVEwmHPCoEfLd/qeT7QPivFcRJjGs/ZHZrz7A/O4Jv1u7n3nXks3WKL2oQaKwR+9PSEpQB0apHqOIkxjes7p7fi2t65TFi0hWtenmVTV4cYKwR+VLK3DIDk+IDO3GFM0BERnryyO9MfGkhstHDrG3NskroQYoXAT3aXlrOvrJJu2fZ8wESu3IwkXrmxkA27Snnw/W9swFmIsELgJ//62rPUwhVn2ERzJrL1zG3GdX1ymbx0G/2enMzYbze7jmQaYIXATw6We975XNenreMkxrj3xNBuvHlrb1o1TeTud77mqfFLqbQeRUHLCoGffLNhD3kZSaTY8wFjEBHO75jJR/eey0VdW/DStFUMeHYqExdtcR3N1MEKgR9UVyufLt5Kp5bWW8iY2uJionjx+rN4+YazaJoYy11/n8s1L8+kaI1NZR1M7O2rHyze7Ok3nd/cxg8Yc7ToKOHi01pyXkFzXplezPtFG7ju1a8Y3CWL09ukcXqbpnTPbkpqgk3L4ooVAj+Y4313870zsx0nMSZ4JcXF8JPBHbmpXx6/G7eE2at3Mm6Bp6lIBAqyUhjcpQXD+7YlOy3RcdrIIqqhNWtgYWGhFhUVuY5xhLwRY0mKi2bx40NcRzEmpOw8UM63G3bz7YY9fL5iO3PX7SJK4OGLO3P7efm25rcfichcVS2s65zdEZyidTtKASiw0cTGnLD05DgGdMpiQKcs7htUwMbdB3ngvfn8btwS/vrFaq7o0ZrLu7ema+smREdZUQgUKwSn6JPFnlvbp67s7jiJMaEvOy2RN2/tw/tz1zNx0VZem7Gal6cVkxAbReeWTTitdRMuOq0lffLTbSlYP7JCcIqmr9hOakIMna3HkDF+ERcTxfA+bRnepy27DpQzZdk2Fm7cy+LNe/jP/E28/dU64qKj6JGbRr92GVzVsw25GUmuY4c0KwSnYN2OUqYvL+HO/u2sLdOYAGiWHMeVPdtwZU/P/sHyKmYV72Bm8Q5mrtrB85NXMGrKSq7smU1BViqXdG9Jm2ZWFE6UPSw+BQOemcKaHaXMeHggOen2zWdMYysu2c/zk1cwbXkJu0sriIuJ4ofn5XNNYS6b9xykrLKafu0ziI22IVP2sDgADpRVsmZHKc1T4qwIGONIu8wUnh92JgDrd5by+MeL+fPUVYyasqrmmozkOM4taE6HzBQKWqTQpVUTcpolEWUPn2tYIThJb85cC8CL15/lOIkxBiAnPYm/3FjI+p2lTF6ylaS4GBLjopmwaAtFa3bxn/mbaq5NTYjhpn55DOycxeltmkb8HYM1DZ2kvBFjASj+/aX2zsKYEHCgrJJVJftZvGkv4xduYdryEgBaNU2gX7sM2mUm07V1EwZ0zArLn2lrGvKzDbtKa7bD8RvGmHCUHB/jndIijWG9cynZV8aMFSV89M0mZhbv4IN5nqnkC7JS6JWfTqcWqVx1VpuImEjS7ghOwi//vZDRc9Yx7aGBtLah8MaEhdLySj5dvJW3Z61j6Za97D1USZOEGH5QmMOATln0ym9GfEzojl2wOwI/OlRRxVuz1vK9M7OtCBgTRpLiYhjaI5uhPbJRVSYu2sLbX63jzZlrefXz1STGRnN2+wx65KSRk57kfSWSmRIf8t3HrRCcoLe/WgfYSmTGhDMRYUi3Vgzp1orS8kpmrtrB1GUlTFtewuSl2464NiE2ipxmnsLQplkiTRNjSY6PITkumuT4GJLiYkiJjyE53rPfokkCTRODa6ZVKwQnoLKqmqfHL6Vzy1QGds5yHccY0wiS4mIY1KUFg7q0ADytAht2lbJuZynrdx5k/U7v9q6DzFmzk/1llTTU4p6WFEtuehK56Um0appAYlwMSXHRJMVFkxgbTZJ3P9F7LCU+hryM5IA9k7RCcALu+vtcyququX9QgesoxhhHEmKj6ZCVSoesuqeVUVUOVlRxoKyKA2WVHCivpLS8iv1llew/VMnmPQdZu8NTPBZs3MOkJVs5VNHwMp656Uk8elkXLj6tpb//SlYIfDWreAeTlnhuCQPxH2GMCQ8i4n1HH0NmarxPH1Nd7SkepeVVHCyvorSikoOHt8urKNlfxpj5m0iOC8yvbCsEPthfVsmD739DXHQURb8cbF1GjTF+FRUlnucKx+mqem3v3IB9fSsEPvjd2MVs3H2Q9+/sRxNbTs8YE2Yie1y1D0ZOWs4/Zq/njvPbUZiX7jqOMcb4nRWC4xjzzSZGTloBwM8u7Og4jTHGBIY1DdWhulp5euJSXp2xmo4tUvjHD/uG9IhCY4w5noDeEYjIEBFZJiIrRWREHefjReRd7/mvRCQvkHl8sWb7AYa/+hUvTyvmuz2yef/Os8lI8e3JvzHGhKKA3RGISDQwCrgQ2ADMEZExqrq41mW3AbtUtYOIDAOeBq4JVKajVVcruw9WMHv1DtbvPMi7RetZuW0/qfEx/P573bm2d07IDx03xpiGBLJpqDewUlWLAURkNDAUqF0IhgK/9m7/E/iTiIgGYCa89+as56XpqyirqPYO9qikrPLYQRxntGnKyzcU0rJpgr8jGGNMUApkIcgG1tfa3wD0qe8aVa0UkT1ABrC99kUicgdwB0Bu7sn1pW2WHEeXVk1IiIkmMS7Ks2hFbDSpCTG0bJpA9+ympCXFBd0cIMYYE2gh8bBYVV8BXgHPNNQn8zku7NqCC7u28GsuY4wJB4F8WLwRyKm138Z7rM5rRCQGaArsCGAmY4wxRwlkIZgDFIhIvojEAcOAMUddMwa4ybv9feCzQDwfMMYYU7+ANQ152/zvASYC0cBfVXWRiDwOFKnqGOA14C0RWQnsxFMsjDHGNKKAPiNQ1XHAuKOOPVZr+xBwdSAzGGOMOT6bYsIYYyKcFQJjjIlwVgiMMSbCWSEwxpgIJ6HWW1NESoC1tQ4156iRyEHKcvpfqGS1nP5lOU9OW1XNrOtEyBWCo4lIkaoWus7REMvpf6GS1XL6l+X0P2saMsaYCGeFwBhjIlw4FIJXXAfwkeX0v1DJajn9y3L6Wcg/IzDGGHNqwuGOwBhjzCmwQmCMMREupAuBiAwRkWUislJERrjOUxcRyRGRKSKyWEQWicj9rjMdj4hEi8g8EfnYdZb6iEiaiPxTRJaKyBIR6ec6U11E5Kfe//OFIvIPEQmK9U9F5K8isk1EFtY6li4in4rICu+fzVxm9GaqK+cz3v/3b0XkQxFJcxjxcKZjctY694CIqIg0d5HNVyFbCEQkGhgFXAJ0Ba4Vka5uU9WpEnhAVbsCfYG7gzTnYfcDS1yHaMDzwARV7QycQRDmFZFs4D6gUFW74ZmKPVimWX8DGHLUsRHAZFUtACZ79117g2Nzfgp0U9XTgeXAI40dqg5vcGxORCQHuAhY19iBTlTIFgKgN7BSVYtVtRwYDQx1nOkYqrpZVb/2bu/D80sr222quolIG+Ay4FXXWeojIk2B8/GsZYGqlqvqbqeh6hcDJHpX30sCNjnOA4CqTsez/kdtQ4G/ebf/Bny3MTPVpa6cqvqJqlZ6d2fhWfnQqXr+PQH+F3gYCPoeOaFcCGoWvvfaQJD+gj1MRPKAM4GvHEepz0g837jVjnMcTz5QArzubcJ6VUSSXYc6mqpuBJ7F825wM7BHVT9xm+q4WqjqZu/2FiAUFvi+FRjvOkRdRGQosFFVv3GdxRehXAhCioikAP8CfqKqe13nOZqIXA5sU9W5rrM0IAboCbyoqmcCBwiOZowjeNvYh+IpXK2BZBG53m0q33iXiw3qd7Ei8iieZte3XWc5mogkAb8AHmvo2mARyoWgZuF7rzbeY0FHRGLxFIG3VfUD13nqcQ5whYiswdPMdoGI/N1tpDptADao6uG7qn/iKQzBZjCwWlVLVLUC+AA423Gm49kqIq0AvH9uc5ynXiJyM3A5MDxI1zhvj+cNwDfen6c2wNci0tJpquMI5UIwBygQkXwRicPzIG6M40zHEBHB0569RFWfc52nPqr6iKq2UdU8PP+Wn6lq0L2DVdUtwHoR6eQ9NAhY7DBSfdYBfUUkyfs9MIggfKhdyxjgJu/2TcB/HGapl4gMwdN8eYWqlrrOUxdVXaCqWaqa5/152gD09H7vBqWQLQTeB0b3ABPx/IC9p6qL3Kaq0znADXjeYc/3vi51HSrE3Qu8LSLfAj2A37uNcyzvHcs/ga+BBXh+1oJiygER+QcwE+gkIhtE5DbgKeBCEVmB527mKZcZod6cfwJSgU+9P0svOQ1JvTlDik0xYYwxES5k7wiMMcb4hxUCY4yJcFYIjDEmwlkhMMaYCGeFwBhjIlyM6wDGBBsRqcLT5fOwdGCMqt7jKJIxAWWFwJhjHVTVHod3vCNZC52lMSbArGnImBMgInki8pl3PvzJIpLrPf6GiLwkIkUistw7dxMikiAir4vIAu8keQO9x28WkZJagwzvc/n3MpHN7giMOTEvAH9T1b+JyK3A//HfKZvz8EyP3h6YIiIdgLvxzOPWXUQ6A5+ISEfv9e9ac5MJBnZHYMyJ6Qe8491+Czi31rn3VLVaVVcAxUBn7/m/A6jqUmAt0BFjgogVAmP85+j5Wmz+FhMSrBAYc2K+5L9LTg4HZtQ6d7WIRIlIe6AdsMx7fjiAt0ko13vcmKBhzwiMOTH34lkd7SE8K6XdUuvcOmA20AS4S1UPicifgRdFZAGehVRuVtUyz8zUxgQHm33UGD8QkTeAj1X1n66zGHOirGnIGGMinN0RGGNMhLM7AmOMiXBWCIwxJsJZITDGmAhnhcAYYyKcFQJjjIlw/w+G4TsgFNkoQwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(5.03515, 0.4127513862016769)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t, g, t_best, g_best = find_best_split(X[\"MedInc\"].values, y, task=\"regression\", feature_type=\"real\")\n",
    "plt.plot(t, g)\n",
    "plt.xlabel(\"Порог\")\n",
    "plt.ylabel(\"Ошибка\")\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Найдите лучший, с вашей точки зрения, предикат первой вершины решающего дерева."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MedInc'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[np.argmax([find_best_split(X[c].values, y, task=\"regression\", feature_type=\"real\")[3] for c in X.columns])]\n",
    "# Многовато всего, но фактически ищем максимум по критерию информативности и выводим соответствующий столбец "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.2 (1 балл)** Разберитесь с написанным кодом решающего дерева, заполните пропуски в коде и реализуйте недостающий метод `_predict_node()`.\n",
    "\n",
    "Построение дерева осуществляется согласно базовому жадному алгоритму, предложенному в лекции в разделе «Построение дерева».\n",
    "- **Выбор лучшего разбиения** необходимо производить по критерию Джини.\n",
    "- **Критерий останова:** все объекты в листе относятся к одному классу или ни по одному признаку нельзя разбить выборку.\n",
    "- **Ответ в листе:** наиболее часто встречающийся класс в листе.\n",
    "\n",
    "В задаче также предлагается получить два бонуса, по баллу на каждый!\n",
    "\n",
    "- **Реализуйте способ обрабатывать пропуски в даннх и реализуйте его, пояснив свои действия.**\n",
    "- **Реализуйте метод оценки важности признаков.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        feature_types: Union[List[str], np.ndarray], \n",
    "        max_depth: int = None, \n",
    "        min_samples_split: int = None, \n",
    "        min_samples_leaf: int = None,\n",
    "        task: str = \"classification\"\n",
    "    ) -> None:\n",
    "        \n",
    "        if np.any(list(map(lambda x: x != \"real\" and x != \"categorical\", feature_types))):\n",
    "            raise ValueError(\"There is unknown feature type\")\n",
    "\n",
    "        # В этой переменной будем хранить узлы решающего дерева. Каждая вершина хранит в себе идентификатор того,\n",
    "        # является ли она листовой. Листовые вершины хранят значение класса для предсказания, нелистовые - правого и\n",
    "        # левого детей (поддеревья для продолжения процедуры предсказания)\n",
    "        self._tree = {}\n",
    "        \n",
    "        # типы признаков (категориальные или числовые)\n",
    "        self._feature_types = feature_types\n",
    "        \n",
    "        # гиперпараметры дерева\n",
    "        self._max_depth = max_depth\n",
    "        self._min_samples_split = min_samples_split\n",
    "        self._min_samples_leaf = min_samples_leaf\n",
    "        self.task = task\n",
    "        \n",
    "        # Переменная, если вы решите делать бонус\n",
    "        self._feature_importances = {}\n",
    "        \n",
    "\n",
    "    def _fit_node(\n",
    "        self, \n",
    "        sub_X: np.ndarray, \n",
    "        sub_y: np.ndarray, \n",
    "        node: dict\n",
    "    ) -> None:\n",
    "        \n",
    "        # критерий останова\n",
    "        if np.all(sub_y == sub_y[0]):\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = sub_y[0]\n",
    "            return\n",
    "\n",
    "        feature_best, threshold_best, gini_best, split = None, None, None, None\n",
    "        for feature in range(sub_X.shape[1]):\n",
    "            feature_type = self._feature_types[feature]\n",
    "            categories_map = {}\n",
    "\n",
    "            # подготавливаем признак для поиска оптимального порога\n",
    "            if feature_type == \"real\":\n",
    "                feature_vector = sub_X[:, feature]\n",
    "            elif feature_type == \"categorical\":\n",
    "                # здесь могла быть реализация более сложного подхода к обработке категориального признака\n",
    "                feature_vector = sub_X[:, feature]\n",
    "            else:\n",
    "                raise ValueError(\"type плохой\")\n",
    "\n",
    "            # ищем оптимальный порог\n",
    "            _, _, threshold, gini = find_best_split(feature_vector, sub_y, self.task, feature_type)\n",
    "            \n",
    "            if gini_best is None or gini > gini_best:\n",
    "                feature_best = feature\n",
    "                gini_best = gini\n",
    "\n",
    "                # split - маска на объекты, которые должны попасть в левое поддерево\n",
    "                if feature_type == \"real\":\n",
    "                    threshold_best = threshold\n",
    "                    split = feature_vector < threshold\n",
    "                elif feature_type == \"categorical\":\n",
    "                    # в данной реализации это просто значение категории\n",
    "                    threshold_best = threshold\n",
    "                    split = feature_vector == threshold\n",
    "                else:\n",
    "                    raise ValueError\n",
    "\n",
    "        # записываем полученные сплиты в атрибуты класса\n",
    "        if feature_best is None:\n",
    "            node[\"type\"] = \"terminal\"\n",
    "            node[\"class\"] = Counter(sub_y).most_common(1)[0][0]\n",
    "            return\n",
    "\n",
    "        node[\"type\"] = \"nonterminal\"\n",
    "\n",
    "        node[\"feature_split\"] = feature_best\n",
    "        if self._feature_types[feature_best] == \"real\":\n",
    "            node[\"threshold\"] = threshold_best\n",
    "        elif self._feature_types[feature_best] == \"categorical\":\n",
    "            node[\"category_split\"] = threshold_best\n",
    "        else:\n",
    "            raise ValueError\n",
    "            \n",
    "        node[\"left_child\"], node[\"right_child\"] = {}, {}\n",
    "        self._fit_node(sub_X[split], sub_y[split], node[\"left_child\"])\n",
    "        self._fit_node(sub_X[np.logical_not(split)], sub_y[np.logical_not(split)], node[\"right_child\"])\n",
    "\n",
    "    def _predict_node(self, x: np.ndarray, node: dict) -> int:\n",
    "        \"\"\"\n",
    "        Предсказание начинается с корневой вершины дерева и рекурсивно идёт в левое или правое поддерево в зависимости от значения\n",
    "        предиката на объекте. Листовая вершина возвращает предсказание.\n",
    "        :param x: np.array, элемент выборки\n",
    "        :param node: dict, вершина дерева\n",
    "        \"\"\"\n",
    "        if node[\"type\"] == \"terminal\":\n",
    "            return node[\"class\"]\n",
    "        if self._feature_types[node[\"feature_split\"]] == \"real\":\n",
    "            if x[node[\"feature_split\"]] < node[\"threshold\"]:\n",
    "                return self._predict_node(x, node[\"left_child\"])\n",
    "            else:\n",
    "                return self._predict_node(x, node[\"right_child\"])\n",
    "        if x[node[\"feature_split\"]] == node[\"category_split\"]:\n",
    "            return self._predict_node(x, node[\"left_child\"])\n",
    "        return self._predict_node(x, node[\"right_child\"])\n",
    "\n",
    "    def fit(self, X: np.ndarray, y: np.ndarray) -> None:\n",
    "        self._fit_node(X, y, self._tree)\n",
    "\n",
    "    def predict(self, X: np.ndarray) -> np.ndarray:\n",
    "        predicted = []\n",
    "        for x in X:\n",
    "            predicted.append(self._predict_node(x, self._tree))\n",
    "            \n",
    "        return np.array(predicted)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.3 (1 балл)** Загрузите таблицу `students.csv` (это немного преобразованный датасет [User Knowledge](https://archive.ics.uci.edu/ml/datasets/User+Knowledge+Modeling)). В ней признаки объекта записаны в первых пяти столбцах, а в последнем записана целевая переменная (класс: 0 или 1). Постройте на одном изображении пять кривых \"порог — значение критерия Джини\" для всех пяти признаков. Отдельно визуализируйте диаграммы рассеяния \"значение признака — класс\" для всех пяти признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './students.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32md:\\Projects\\study.ida\\ML - Intro\\hw07-trees-rf.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/Projects/study.ida/ML%20-%20Intro/hw07-trees-rf.ipynb#X33sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m\"\u001b[39;49m\u001b[39m./students.csv\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/Projects/study.ida/ML%20-%20Intro/hw07-trees-rf.ipynb#X33sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m data\u001b[39m.\u001b[39misna()\u001b[39m.\u001b[39many()\n",
      "File \u001b[1;32mc:\\Users\\TechnoDX\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[39m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\TechnoDX\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\TechnoDX\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\TechnoDX\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[1;32mc:\\Users\\TechnoDX\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[39m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[39m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[39m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(  \u001b[39m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m     f,\n\u001b[0;32m   1220\u001b[0m     mode,\n\u001b[0;32m   1221\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1222\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1223\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[0;32m   1224\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[0;32m   1225\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[0;32m   1226\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[0;32m   1227\u001b[0m )\n\u001b[0;32m   1228\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\TechnoDX\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[0;32m    787\u001b[0m             handle,\n\u001b[0;32m    788\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[0;32m    789\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[0;32m    790\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[0;32m    791\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    792\u001b[0m         )\n\u001b[0;32m    793\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './students.csv'"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(\"./students.csv\")\n",
    "data.isna().any()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Исходя из кривых значений критерия Джини, по какому признаку нужно производить деление выборки на два поддерева? Согласуется ли этот результат с визуальной оценкой диаграмм рассеяиния? Как бы охарактеризовали вид кривой для \"хороших\" признаков, по которым выборка делится почти идеально? Чем отличаются кривые для признаков, по которым деление практически невозможно?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 2.4 (1 балл)** Протестируйте свое решающее дерево на датасете [mushrooms](https://archive.ics.uci.edu/ml/datasets/Mushroom). \n",
    "\n",
    "1. Скачайте таблицу `agaricus-lepiota.data` (из [Data Folder](https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/)), \n",
    "2. Считайте таблицу при помощи `pandas`,\n",
    "3. Примените к каждому столбцу `LabelEncoder` (из `sklearn`), чтобы преобразовать строковые имена категорий в натуральные числа. \n",
    "\n",
    "Первый столбец — это целевая переменная (e — edible, p — poisonous) Мы будем измерять качество с помощью accuracy, так что нам не очень важно, что будет классом 1, а что — классом 0. Обучите решающее дерево на половине случайно выбранных объектов (признаки в датасете категориальные) и сделайте предсказания для оставшейся половины. Вычислите accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Часть 3: Бэггинг и случайный лес (4 балла)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данной части мы будем работать [с задачей предсказания диабета у пациента](https://www.kaggle.com/uciml/pima-indians-diabetes-database/data). Посмотрим на работу бэггинга над решающими деревьями и случайного леса, сравним их работу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('diabetes.csv')\n",
    "print(f\"Dataset shape: {data.shape}\")\n",
    "data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на распределение целевой переменной"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Outcome'].hist()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.1 (0.5 балла)** Разделите данные на признаки и целевую переменную. Разбейте датасет на обучающую и тестовую части в отношении 7:3. Затем разделите обучающую выборку на обучающую-обучающую и обучающую-валидационную в соотношении 7:3 (то есть в итоге должно получиться три выборки: обучающая-обучающая (0.49 от исходного датасета), обучающая-валидационная (0.21 от исходного датасета) и тестовая (0.3 от исходного датасета)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.2 (1 балл)** На обучающей-валидационной выборке подберите оптимальные значения гиперпараметров `max_depth` и `min_samples_leaf` для `DecisionTreeClassifier`. Для этого:\n",
    "1. Создайте списки с возможными значениями для перебора.\n",
    "2. Для каждой пары значений обучите дерево на обучающей-обучающей выборке и определите качество на обучающей-валидационной выборке. В качестве критерия будем использовать `f1-меру`.\n",
    "3. Выберите ту пару значений, которая даёт наилучшее качество на обучающей-валидационной выборке. \n",
    "\n",
    "\n",
    "Обучите решающее дерево с подобранными гиперпараметрами на **полной обучающей** выборке. Оцените качество классификации на тестовой выборке по метрикам `accuracy`, `precision` и `recall`, `auc_roc`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.3 (0.5 балла)** Обучите [`BaggingClassifier`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html) на 50 деревьях на **полной обучающей** выборке. Оцените качество классификации на тестовой выборке по тем же метрикам."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.4 (1 балл)** Выполните кросс-валидацию на полной обучающей выборке и подберите оптимальные значения гиперпараметров `max_depth` и `min_samples_split` для `Random Forest` с 50 деревьями. Для этого:\n",
    "\n",
    "1. Создайте списки с возможными значениями для перебора.\n",
    "2. Для каждой пары значений проведите кросс-валидацию на полной обучающей выборке. Количество разбиений выберите на ваш вкус. В качестве критерия будем использовать `f1-меру`. Усредните значение критерия по всем прогонам кросс-валидации. \n",
    "3. Выберите ту пару значений, которая даёт наилучшее среднее качество. \n",
    "\n",
    "Обучите случайный лес с подобранными гиперпараметрами на **полной обучающей** выборке. Оцените качество классификации по тем же метрикам. Какая из трёх построенных моделей показала себя лучше?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.5 (0.5 балла)** Постройте график зависимости AUC ROC на тестовой выборке от числа деревьев (`n_estimators`) для случайного леса, обучаемого на **полной обучающей** выборке. Какие выводы можно сделать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Задание 3.6 (0.5 балла)** Для лучшей модели случайного леса из **Задания 3.4** посчитайте важность признаков и постройте bar plot. Какой признак оказался самым важным для определения диабета?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ᕕ(╭ರ╭ ͟ʖ╮•́)⊃¤=(————"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
